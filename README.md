# ü©∫ Regress√£o Regularizada para Previs√£o do Custo do Seguro Sa√∫de (R/MLOps)

## üéØ Objetivo do Projeto

Este projeto demonstra a aplica√ß√£o de modelos de **Regress√£o Linear Regularizada (Ridge e Lasso)** usando R para construir um modelo est√°vel e interpret√°vel capaz de prever os custos anuais de seguro sa√∫de (`charges`) com base em caracter√≠sticas demogr√°ficas e de sa√∫de dos segurados (idade, BMI, fumante, etc.).

O principal foco √© encontrar o melhor ponto de equil√≠brio no **Trade-off Vi√©s-Vari√¢ncia** e utilizar a **Regress√£o Lasso** para realizar a **Sele√ß√£o Autom√°tica de Vari√°veis**, simplificando o modelo final.

## üîë Conceitos Fundamentais Abordados

* **Regress√£o Lasso (L1):** Aplica uma penalidade de valor absoluto ($\lambda \sum |\beta_j|$) que **zera** os coeficientes das vari√°veis irrelevantes, promovendo a parcim√¥nia.
* **Regress√£o Ridge (L2):** Aplica uma penalidade de quadrado ($\lambda \sum \beta_j^2$) que **encolhe** todos os coeficientes em dire√ß√£o a zero, aumentando a estabilidade do modelo.
* **Valida√ß√£o Cruzada (CV):** Utilizada com o pacote `glmnet` para otimizar o hiperpar√¢metro **Lambda ($\lambda$)** e encontrar o melhor modelo generaliz√°vel.

## ‚öôÔ∏è Estrutura do Reposit√≥rio

* `insurance.csv`: Dataset de entrada original.
* `assets/`: Cont√©m os gr√°ficos de Valida√ß√£o Cruzada dos modelos.
    * `lasso_cv_path.png`
    * `ridge_cv_path.png`
* `01_Model_Regularization.ipynb`: Notebook principal em R com as etapas de pr√©-processamento, treinamento e avalia√ß√£o.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** R
* **Ambiente:** VS Code / Jupyter Notebook
* **Pacotes Principais:** `glmnet`, `caret`, `readr`, `Matrix`

---

## üìä Resultado Esperado

O resultado √© um modelo param√©trico que n√£o apenas prev√™ o custo do seguro com alta precis√£o (baixo **RMSE**), mas tamb√©m oferece alta **interpretabilidade**, permitindo que a seguradora entenda exatamente o impacto de cada fator de risco (como ser fumante ou ter alto BMI) na estrutura de custos.


## üìä Resultados obtido e An√°lise

O projeto utilizou 10-fold Cross-Validation para otimizar os modelos e o **RMSE** (Root Mean Squared Error) no *set* de teste para compara√ß√£o de desempenho.

### I. Otimiza√ß√£o e Sele√ß√£o de Vari√°veis (Lasso)

O Lasso encontrou o $\lambda$ √≥timo ($57.47$) e realizou a sele√ß√£o de vari√°veis:

* **Lambda √ìtimo:** $57.46561$
* **Sele√ß√£o:** O coeficiente da vari√°vel `regionnorthwest` foi **zerado** ($\mathbf{.}$), indicando que esta *feature* n√£o contribui significativamente para o modelo de custo no n√≠vel de penalidade ideal.

| Vari√°vel | Coeficiente no $\lambda$ √ìtimo |
| :--- | :--- |
| (Intercept) | -11440.6780 |
| age | 255.1052 |
| smokeryes | **23800.9871** |
| regionnorthwest | **.** (Zerado) |

**Gr√°fico do Caminho dos Coeficientes Lasso:**

![Gr√°fico de Caminho de Coeficientes Lasso com CV](./assets/lasso_cv_path.png)

### II. Otimiza√ß√£o Ridge (Estabilidade)

O Ridge encontrou um $\lambda$ √≥timo mais alto ($958.58$) e encolheu todos os coeficientes, mas manteve todos eles diferentes de zero.

* **Lambda √ìtimo:** $958.5842$

**Gr√°fico do Caminho dos Coeficientes Ridge:**

![Gr√°fico de Caminho de Coeficientes Ridge com CV](./assets/ridge_cv_path.png)

### III. Compara√ß√£o Final de Desempenho (RMSE)

| Modelo | RMSE no Set de Teste | Conclus√£o |
| :--- | :--- | :--- |
| **Lasso ($\alpha=1$)** | **5763.20 R\$** | Melhor Desempenho e Mais Interpretabilidade. |
| **Ridge ($\alpha=0$)** | 5792.96 R\$ | RMSE marginalmente superior. |

### Conclus√£o do Projeto

O **Modelo Lasso** foi o escolhido por oferecer a **melhor acur√°cia de previs√£o (menor RMSE)** e, simultaneamente, o benef√≠cio de **interpretabilidade** ao identificar e eliminar preditores menos relevantes (`regionnorthwest`). O erro m√©dio de previs√£o no custo do seguro √© de aproximadamente **R$ 5.763,20**.